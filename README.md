## End-to-End Medical Insurance Premium Prediction Using DVC Pipeline

Project Overview
This project aims to predict medical insurance premiums based on individual health and demographic data. By leveraging a complete Machine Learning Operations (MLOps) pipeline with Data Version Control (DVC), the project ensures reproducibility, scalability, and efficient model management.


### ​ Project Structure

```bash
End-to-end-Medical-Insurance-project-using-DVC-Pipeline/
├── .dvc/                      # DVC internal files
├── .dvcignore                 # Files/directories ignored by DVC
├── .gitignore                 # Files/directories ignored by Git
├── data/                      # Raw and processed data
├── dvc_plots/                 # Visualizations generated by DVC
├── dvclive/                   # Live metrics and logs
├── notebook/                  # Jupyter notebooks for EDA and prototyping
├── src/                       # Source code for pipeline stages
│   ├── data_ingestion.py
│   ├── data_validation.py
│   ├── data_transformation.py
│   ├── model_trainer.py
│   ├── model_evaluation.py
│   └── prediction_pipeline.py
├── experiments_tracking.py    # Script for tracking experiments
├── experiments_tracking.py.dvc
├── dvc.yaml                   # DVC pipeline configuration
├── dvc.lock                   # DVC pipeline lock file
├── params.yaml                # Hyperparameters and configurations
├── requirements.txt           # Python dependencies
└── README.md                  # Project documentation

```

##  Setup Instructions
1. Clone the Repository :-
   
```
git clone https://github.com/SandeepSuthar169/End-to-end-Medical-Insurance-project-using-DVC-Pipeline.git
```


3. Create and Activate a Virtual Environment

```
python -m venv venv
venv\Scripts\activate
```

3. Install Dependencies

```
pip install -r requirements.txt
```

4. Initialize DVC and Pull Data

```
dvc init
dvc pull
```
- Ensure you have access to the remote storage configured in the DVC setup.


5. Run the Pipeline

```
dvc repro
```
- This command will execute all stages defined in the dvc.yaml file, from data ingestion to model evaluation.

 ##  Pipeline Stages 
 - Data Ingestion: Loads raw data into the project.

- Data Validation: Checks data quality and integrity.

- Data Transformation: Processes and prepares data for modeling.

- Model Training: Trains the machine learning model.

- Model Evaluation: Assesses model performance using appropriate metrics.

Each stage is modularized in the src/ directory and is configured in the dvc.yaml file.



 ## Experiment Tracking
Experiments are tracked using DVC's experiment tracking features. Metrics and parameters are logged and can be visualized using:


`dvc exp show`

## Visualizations
DVC generates plots to visualize metrics over time. To view these plots:

`dvc plots show`

## Configuration
Hyperparameters and other configurations are managed in the params.yaml file. Modify this file to experiment with different settings.
